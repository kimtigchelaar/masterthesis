{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import time\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas import DataFrame\n",
    "from matplotlib import gridspec\n",
    "from scipy.stats import zscore\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment out the data files that you don't want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/N-CMAPSS_DS01-005.h5'\n",
    "# filename = 'data/N-CMAPSS_DS04.h5'\n",
    "# filename = 'data/N-CMAPSS_DS08c-008.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Operation time (min):  0.03958333333333333\n",
      "\n",
      "W shape: (7641868, 4)\n",
      "X_s shape: (7641868, 14)\n",
      "X_v shape: (7641868, 14)\n",
      "T shape: (7641868, 10)\n",
      "A shape: (7641868, 4)\n"
     ]
    }
   ],
   "source": [
    "# time tracking\n",
    "t = time.process_time()  \n",
    "\n",
    "# loading data\n",
    "with h5py.File(filename, 'r') as hdf:\n",
    "        \n",
    "        # development set\n",
    "        W_dev = np.array(hdf.get('W_dev'))             # W\n",
    "        X_s_dev = np.array(hdf.get('X_s_dev'))         # X_s\n",
    "        X_v_dev = np.array(hdf.get('X_v_dev'))         # X_v\n",
    "        T_dev = np.array(hdf.get('T_dev'))             # T\n",
    "        Y_dev = np.array(hdf.get('Y_dev'))             # RUL  \n",
    "        A_dev = np.array(hdf.get('A_dev'))             # Auxiliary\n",
    "\n",
    "        # test set\n",
    "        W_test = np.array(hdf.get('W_test'))           # W\n",
    "        X_s_test = np.array(hdf.get('X_s_test'))       # X_s\n",
    "        X_v_test = np.array(hdf.get('X_v_test'))       # X_v\n",
    "        T_test = np.array(hdf.get('T_test'))           # T\n",
    "        Y_test = np.array(hdf.get('Y_test'))           # RUL  \n",
    "        A_test = np.array(hdf.get('A_test'))           # Auxiliary\n",
    "        \n",
    "        # varnams\n",
    "        W_var = np.array(hdf.get('W_var'))\n",
    "        X_s_var = np.array(hdf.get('X_s_var'))  \n",
    "        X_v_var = np.array(hdf.get('X_v_var')) \n",
    "        T_var = np.array(hdf.get('T_var'))\n",
    "        A_var = np.array(hdf.get('A_var'))\n",
    "        \n",
    "        # from np.array to list dtype U4/U5\n",
    "        W_var = list(np.array(W_var, dtype='U20'))\n",
    "        X_s_var = list(np.array(X_s_var, dtype='U20'))  \n",
    "        X_v_var = list(np.array(X_v_var, dtype='U20')) \n",
    "        T_var = list(np.array(T_var, dtype='U20'))\n",
    "        A_var = list(np.array(A_var, dtype='U20'))\n",
    "                          \n",
    "W = np.concatenate((W_dev, W_test), axis=0)  \n",
    "X_s = np.concatenate((X_s_dev, X_s_test), axis=0)\n",
    "X_v = np.concatenate((X_v_dev, X_v_test), axis=0)\n",
    "T = np.concatenate((T_dev, T_test), axis=0)\n",
    "Y = np.concatenate((Y_dev, Y_test), axis=0) \n",
    "A = np.concatenate((A_dev, A_test), axis=0) \n",
    "    \n",
    "print('')\n",
    "print(\"Operation time (min): \" , (time.process_time()-t)/60)\n",
    "print('')\n",
    "print (\"W shape: \" + str(W.shape))\n",
    "print (\"X_s shape: \" + str(X_s.shape))\n",
    "print (\"X_v shape: \" + str(X_v.shape))\n",
    "print (\"T shape: \" + str(T.shape))\n",
    "print (\"A shape: \" + str(A.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataframes for training\n",
    "df_A_train = DataFrame(data=A_dev, columns=A_var)             # auxiliary information\n",
    "df_W_train = DataFrame(data=W_dev, columns=W_var)             # operative conditions \n",
    "df_X_s_train = DataFrame(data=X_s_dev, columns=X_s_var)       # sensor readings\n",
    "df_X_v_train = DataFrame(data=X_v_dev, columns=X_v_var)       # virtual sensors\n",
    "df_T_train = DataFrame(data=T_dev, columns=T_var)             # degradation\n",
    "df_Y_train = DataFrame(data=Y_dev)                            # RUL\n",
    "\n",
    "# creating the dataframes for testing\n",
    "df_A_test = DataFrame(data=A_test, columns=A_var)             # auxiliary information\n",
    "df_W_test = DataFrame(data=W_test, columns=W_var)             # operative conditions \n",
    "df_X_s_test = DataFrame(data=X_s_test, columns=X_s_var)       # sensor readings\n",
    "df_X_v_test = DataFrame(data=X_v_test, columns=X_v_var)       # virtual sensors\n",
    "df_T_test = DataFrame(data=T_test, columns=T_var)             # degradation\n",
    "df_Y_test = DataFrame(data=Y_test)                            # RUL\n",
    "\n",
    "# concatinated DataFrames \n",
    "df_train = pd.concat([df_W_train, df_X_s_train, df_X_v_train, df_T_train, df_Y_train, df_A_train], axis=1)\n",
    "df_test = pd.concat([df_W_test, df_X_s_test, df_X_v_test, df_T_test, df_Y_test, df_A_test], axis=1)\n",
    "df_total = pd.concat([df_train, df_test], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set of data/N-CMAPSS_DS01-005.h5 has 4906636 rows.\n",
      "The test set of data/N-CMAPSS_DS01-005.h5 has 2735232 rows.\n",
      "The combined data of data/N-CMAPSS_DS01-005.h5 has 7641868 rows.\n",
      "\n",
      "\n",
      "The units in the train set of data/N-CMAPSS_DS01-005.h5 are [1.0, 2.0, 3.0, 4.0, 5.0, 6.0].\n",
      "The units in the test set of data/N-CMAPSS_DS01-005.h5 are [7.0, 8.0, 9.0, 10.0].\n"
     ]
    }
   ],
   "source": [
    "print(f\"The train set of {filename} has {df_train.shape[0]} rows.\")\n",
    "print(f\"The test set of {filename} has {df_test.shape[0]} rows.\")\n",
    "print(f\"The combined data of {filename} has {df_total.shape[0]} rows.\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"The units in the train set of {filename} are {df_train.unit.unique().tolist()}.\")\n",
    "print(f\"The units in the test set of {filename} are {df_test.unit.unique().tolist()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alt</th>\n",
       "      <th>Mach</th>\n",
       "      <th>TRA</th>\n",
       "      <th>T2</th>\n",
       "      <th>T24</th>\n",
       "      <th>T30</th>\n",
       "      <th>T48</th>\n",
       "      <th>T50</th>\n",
       "      <th>P15</th>\n",
       "      <th>P2</th>\n",
       "      <th>...</th>\n",
       "      <th>HPC_flow_mod</th>\n",
       "      <th>HPT_eff_mod</th>\n",
       "      <th>HPT_flow_mod</th>\n",
       "      <th>LPT_eff_mod</th>\n",
       "      <th>LPT_flow_mod</th>\n",
       "      <th>0</th>\n",
       "      <th>unit</th>\n",
       "      <th>cycle</th>\n",
       "      <th>Fc</th>\n",
       "      <th>hs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3013.0</td>\n",
       "      <td>0.376362</td>\n",
       "      <td>70.311996</td>\n",
       "      <td>522.314770</td>\n",
       "      <td>618.288596</td>\n",
       "      <td>1470.469798</td>\n",
       "      <td>1849.620676</td>\n",
       "      <td>1269.275585</td>\n",
       "      <td>19.432070</td>\n",
       "      <td>14.484611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3020.0</td>\n",
       "      <td>0.376866</td>\n",
       "      <td>70.311996</td>\n",
       "      <td>522.327145</td>\n",
       "      <td>618.296355</td>\n",
       "      <td>1470.415593</td>\n",
       "      <td>1849.519871</td>\n",
       "      <td>1269.177159</td>\n",
       "      <td>19.431385</td>\n",
       "      <td>14.484683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3025.0</td>\n",
       "      <td>0.377685</td>\n",
       "      <td>70.311996</td>\n",
       "      <td>522.371840</td>\n",
       "      <td>618.336514</td>\n",
       "      <td>1470.453853</td>\n",
       "      <td>1849.566139</td>\n",
       "      <td>1269.167353</td>\n",
       "      <td>19.435163</td>\n",
       "      <td>14.488224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3035.0</td>\n",
       "      <td>0.376992</td>\n",
       "      <td>70.399887</td>\n",
       "      <td>522.282418</td>\n",
       "      <td>618.302173</td>\n",
       "      <td>1470.650929</td>\n",
       "      <td>1850.195069</td>\n",
       "      <td>1269.518670</td>\n",
       "      <td>19.426003</td>\n",
       "      <td>14.477632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3043.0</td>\n",
       "      <td>0.377622</td>\n",
       "      <td>70.399887</td>\n",
       "      <td>522.300605</td>\n",
       "      <td>618.345228</td>\n",
       "      <td>1470.640421</td>\n",
       "      <td>1849.950988</td>\n",
       "      <td>1269.253972</td>\n",
       "      <td>19.427484</td>\n",
       "      <td>14.478114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alt      Mach        TRA          T2         T24          T30  \\\n",
       "0  3013.0  0.376362  70.311996  522.314770  618.288596  1470.469798   \n",
       "1  3020.0  0.376866  70.311996  522.327145  618.296355  1470.415593   \n",
       "2  3025.0  0.377685  70.311996  522.371840  618.336514  1470.453853   \n",
       "3  3035.0  0.376992  70.399887  522.282418  618.302173  1470.650929   \n",
       "4  3043.0  0.377622  70.399887  522.300605  618.345228  1470.640421   \n",
       "\n",
       "           T48          T50        P15         P2  ...  HPC_flow_mod  \\\n",
       "0  1849.620676  1269.275585  19.432070  14.484611  ...           0.0   \n",
       "1  1849.519871  1269.177159  19.431385  14.484683  ...           0.0   \n",
       "2  1849.566139  1269.167353  19.435163  14.488224  ...           0.0   \n",
       "3  1850.195069  1269.518670  19.426003  14.477632  ...           0.0   \n",
       "4  1849.950988  1269.253972  19.427484  14.478114  ...           0.0   \n",
       "\n",
       "   HPT_eff_mod  HPT_flow_mod  LPT_eff_mod  LPT_flow_mod   0  unit  cycle   Fc  \\\n",
       "0    -0.000604           0.0          0.0           0.0  99   1.0    1.0  1.0   \n",
       "1    -0.000604           0.0          0.0           0.0  99   1.0    1.0  1.0   \n",
       "2    -0.000604           0.0          0.0           0.0  99   1.0    1.0  1.0   \n",
       "3    -0.000604           0.0          0.0           0.0  99   1.0    1.0  1.0   \n",
       "4    -0.000604           0.0          0.0           0.0  99   1.0    1.0  1.0   \n",
       "\n",
       "    hs  \n",
       "0  1.0  \n",
       "1  1.0  \n",
       "2  1.0  \n",
       "3  1.0  \n",
       "4  1.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show train dataset\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying what columns to remove per subset of the data (as they don't contain that failure mode)\n",
    "fmodes_DS01 =  ['fan_eff_mod', 'fan_flow_mod', 'LPC_eff_mod', 'LPC_flow_mod',\n",
    "                'HPC_eff_mod', 'HPC_flow_mod', 'HPT_flow_mod', 'LPT_eff_mod', 'LPT_flow_mod']\n",
    "\n",
    "fmodes_DS04 =  ['LPC_eff_mod', 'LPC_flow_mod',\n",
    "                'HPC_eff_mod', 'HPC_flow_mod', 'HPT_eff_mod', 'HPT_flow_mod',\n",
    "                'LPT_eff_mod', 'LPT_flow_mod']\n",
    "\n",
    "fmodes_DS08 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df, fmodes):\n",
    "    '''Pre-processing pipeline for the N-CMAPSS dataset as described in the methodology'''\n",
    "\n",
    "    # renaming RUL column\n",
    "    col = list(df.columns)\n",
    "    col[42]='RUL'\n",
    "    df.columns = col\n",
    "\n",
    "    # dropping columns 'P2' and 'T2'\n",
    "    df = df.drop(columns = [\"P2\", \"T2\"])\n",
    "\n",
    "    # setting rolling window size \n",
    "    window_size = 100\n",
    "\n",
    "    # selecting columns for noise reduction (sensor measurements & virtual readings)\n",
    "    to_reduce = ['TRA', 'T24', 'T30', 'T48', 'T50', 'P15', 'P21', 'P24',\n",
    "       'Ps30', 'P40', 'P50', 'Nf', 'Nc', 'Wf', 'T40', 'P30', 'P45', 'W21',\n",
    "       'W22', 'W25', 'W31', 'W32', 'W48', 'W50', 'SmFan', 'SmLPC', 'SmHPC',\n",
    "       'phi', 'fan_eff_mod', 'fan_flow_mod', 'LPC_eff_mod', 'LPC_flow_mod',\n",
    "       'HPC_eff_mod', 'HPC_flow_mod', 'HPT_eff_mod', 'HPT_flow_mod',\n",
    "       'LPT_eff_mod', 'LPT_flow_mod']\n",
    "    \n",
    "    # part of dataframe that doesn't need noise reduction\n",
    "    no_noise = df[['alt', 'Mach', 'RUL', 'unit', 'cycle', 'Fc', 'hs']]\n",
    "\n",
    "    # calculate rolling average for each column base on window\n",
    "    rolling_avg_df = df[to_reduce].rolling(window=window_size).mean()\n",
    "\n",
    "    # fill in nan values with the original value \n",
    "    for col in to_reduce:\n",
    "        rolling_avg_df.fillna({col: df[col]}, inplace=True)\n",
    "\n",
    "    # concatenate both parts of dataframe back together \n",
    "    df_reduced = pd.concat([no_noise, rolling_avg_df], axis = 1)\n",
    "\n",
    "    # calculating T30 - T24 & adding to dataframe\n",
    "    df_reduced[\"dT_30_24\"] = abs(df_reduced.T30 - df_reduced.T24)\n",
    "\n",
    "    # calculating T50 - T40 & adding to dataframe \n",
    "    df_reduced[\"dT_50_40\"] = abs(df_reduced.T50 - df_reduced.T40)\n",
    "\n",
    "    # applying z-score normalization \n",
    "    df_reduced[to_reduce + [\"dT_30_24\", \"dT_50_40\"]] = df_reduced[to_reduce + [\"dT_30_24\", \"dT_50_40\"]].apply(zscore)\n",
    "\n",
    "    # dropping failure modes not in current subset\n",
    "    df_reduced = df_reduced.drop(columns = fmodes)\n",
    "\n",
    "    return df_reduced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process data & give inactive failure modes of subset as input\n",
    "df_train_processed = preprocessing(df_train, fmodes_DS01)\n",
    "df_test_processed = preprocessing(df_test, fmodes_DS01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_correlation(df, treshold = 0.1):\n",
    "    \"\"\"Filtering out features that have an exteremely low correlation with the target value RUL\"\"\"\n",
    "\n",
    "    # calculate correlations\n",
    "    correlations = df.corr()[['RUL']]\n",
    "\n",
    "    # list of columns to drop \n",
    "    to_drop = []\n",
    "\n",
    "    # filter out correlations not above treshold\n",
    "    for i, row in correlations.iterrows():\n",
    "        feature = i\n",
    "        RUL_c = row[\"RUL\"]\n",
    "\n",
    "        if abs(RUL_c) < treshold or RUL_c == np.nan:\n",
    "            to_drop.append(feature)\n",
    "\n",
    "    # make sure to not drop unit column (is needer for client partitioning)\n",
    "    if \"unit\" in to_drop:\n",
    "        to_drop.remove(\"unit\")\n",
    "\n",
    "    return to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine what columns to drop based on train set\n",
    "to_drop = low_correlation(df_train_processed)\n",
    "\n",
    "# drop the same columns from both train & test\n",
    "df_train_processed = df_train_processed.drop(columns = to_drop)\n",
    "df_test_processed = df_test_processed.drop(columns = to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4906636, 7), (2735232, 7))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if train & test have same number of columns\n",
    "df_train_processed.shape, df_test_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUL</th>\n",
       "      <th>unit</th>\n",
       "      <th>cycle</th>\n",
       "      <th>Fc</th>\n",
       "      <th>hs</th>\n",
       "      <th>SmLPC</th>\n",
       "      <th>HPT_eff_mod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.819682</td>\n",
       "      <td>0.802273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.811191</td>\n",
       "      <td>0.802273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.805529</td>\n",
       "      <td>0.802273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.821695</td>\n",
       "      <td>0.802273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.811291</td>\n",
       "      <td>0.802273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RUL  unit  cycle   Fc   hs     SmLPC  HPT_eff_mod\n",
       "0   99   1.0    1.0  1.0  1.0  1.819682     0.802273\n",
       "1   99   1.0    1.0  1.0  1.0  1.811191     0.802273\n",
       "2   99   1.0    1.0  1.0  1.0  1.805529     0.802273\n",
       "3   99   1.0    1.0  1.0  1.0  1.821695     0.802273\n",
       "4   99   1.0    1.0  1.0  1.0  1.811291     0.802273"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show processed train dataset\n",
    "df_train_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation function for RMSE and R2\n",
    "def evaluate(y_true, y_hat, label = 'test'):\n",
    "    mse = mean_squared_error(y_true, y_hat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(y_true, y_hat)\n",
    "    print('{} set RMSE:{}, R2:{}'.format(label, rmse, variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating trianing & test set\n",
    "X_train = df_train_processed.drop(columns=[\"RUL\"])\n",
    "X_test = df_test_processed.drop(columns=[\"RUL\"])\n",
    "\n",
    "y_train = df_train_processed[\"RUL\"]\n",
    "y_test = df_test_processed[\"RUL\"]\n",
    "\n",
    "# fixing error\n",
    "X_train = X_train.rename(str, axis = \"columns\") \n",
    "X_test = X_test.rename(str, axis = \"columns\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set RMSE:5.06734770713116, R2:0.9638145080488311\n",
      "test set RMSE:16.441812189718675, R2:0.5485254248825864\n"
     ]
    }
   ],
   "source": [
    "# initialize and fit Linear Regression model\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# predict and evaluate\n",
    "y_hat_train = lm.predict(X_train)\n",
    "evaluate(y_train, y_hat_train, 'train')\n",
    "\n",
    "y_hat_test = lm.predict(X_test)\n",
    "evaluate(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set RMSE:0.051791157901648906, R2:0.9999962200651719\n",
      "test set RMSE:6.305085517933128, R2:0.9336079781257516\n"
     ]
    }
   ],
   "source": [
    "# initialize and fit XGB regressor\n",
    "xgb_regressor = XGBRegressor()\n",
    "xgb_regressor.fit(X_train, y_train)\n",
    "\n",
    "# predict and evaluate\n",
    "y_hat_train = xgb_regressor.predict(X_train)\n",
    "evaluate(y_train, y_hat_train, 'train')\n",
    "\n",
    "y_hat_test = xgb_regressor.predict(X_test)\n",
    "evaluate(y_test, y_hat_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set RMSE:0.10759658953505404, R2:0.9999827497954495\n",
      "test set RMSE:11.03473290360531, R2:0.8098335043555979\n"
     ]
    }
   ],
   "source": [
    "# initialize and fit Random Forest regressor\n",
    "rf_regressor = RandomForestRegressor(\n",
    "        criterion='squared_error',\n",
    "        n_estimators=100,\n",
    "        max_depth=20,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    ")\n",
    "\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# predict and evaluate\n",
    "y_hat_train = rf_regressor.predict(X_train)\n",
    "evaluate(y_train, y_hat_train, 'train')\n",
    "\n",
    "y_hat_test = rf_regressor.predict(X_test)\n",
    "evaluate(y_test, y_hat_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
